{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNdvbmDklDOCbHVXjdO2Ehr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KaosElegent/tensorflow-fun/blob/main/tfTutorial1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "434KyCDpHpwg",
        "outputId": "57b7f223-92b5-4f68-d592-fe1001a3d8e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.15.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(\"TensorFlow version:\", tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Refer to the following link for terminology reference: https://developers.google.com/machine-learning/glossary"
      ],
      "metadata": {
        "id": "5ISa6_eWNpfP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "load_data() or train_test_split(), etc. functions split the data into 4 parts: x_train, y_train, x_test, y_test.\n",
        "\n",
        "X stands for the independent variables (x1, x2, x3...)\n",
        "Y stands for the dependent variable (eg. the class we are predicting)"
      ],
      "metadata": {
        "id": "b3FcnqigaOFR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "# Loading MNIST data\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Converting the 0-255 int values to 0-1 float\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "metadata": {
        "id": "2Tan8piaJnsA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Why Sequential?\n",
        "- Sequential models are useful for stacking layers where each layer has 1 input tensor and 1 output tensor.\n",
        "\n",
        "2) What does the layer do?\n",
        "- Alayer is basically a function with a known mathematical structure. This structure is trainable and canbe reused.\n",
        "\n",
        "3) What layers are used in this image classification model?\n",
        "- This model uses 'Flatten', 'Dense' and 'Dropout' layers.\n",
        "\n",
        "4) What does this stack of layers return?\n",
        "- The model returns a 'vector of logits or log-odds scores'.\n",
        "More info can be found here: https://developers.google.com/machine-learning/glossary#logits"
      ],
      "metadata": {
        "id": "NyfRD5yNMkpD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10)\n",
        "])"
      ],
      "metadata": {
        "id": "NspmQznILfrN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test code\n",
        "sample_predictions = model(x_train[:1])\n",
        "sample_predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vFCQJsNOVQu",
        "outputId": "9f531db3-dd06-4340-ef99-2b0282f4b523"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
              "array([[ 0.53169596, -0.92048705, -0.4032669 ,  0.53544474,  0.39081994,\n",
              "        -0.6868503 ,  0.757062  , -0.45413458, -0.5543986 , -0.8083941 ]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) What are the numbers above?\n",
        "- They are called logits.\n",
        "\n",
        "2) What are logits?\n",
        "- Logits are the vector of raw (non-nomralized) preditions that a classification model generates. Normally these are thus passed to a normalization function.\n",
        "\n",
        "3) Are logits always fed to a normalization function?\n",
        "- No. If the model is solving a multi-class classification problem, logits typically becomean input to the 'softmax' function. This functiongenerates a vector of normalized probabilities with 1 value for each possibile class.\n",
        "\n",
        "**Note: It is possible to incorporate the softmax function directly into the activation function of the neurons in the last layer of the network. While this canmake the model's output easier to interpret directly (without doing the following step), it is discouraged. This is ecause it is impossible to provide an exact and numerically stable loss calculation for all models when using a softmax output.**"
      ],
      "metadata": {
        "id": "IoqtYw_aPB7H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test code\n",
        "tf.nn.softmax(sample_predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHWAm1G_PBQH",
        "outputId": "d9ea31fe-cba7-4127-a0c9-1630df3c522a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
              "array([[0.16611472, 0.03888061, 0.06521671, 0.16673861, 0.14428675,\n",
              "        0.04911342, 0.2081054 , 0.06198225, 0.05606905, 0.0434925 ]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss Function\n",
        "Now that we have a model, we need to train it. To do so, we'll need to use a loss function. For this model, we'll use: losses.SparseCategoricalCrossentropy().\n",
        "\n",
        "1) What are this loss function's inputs and outputs?\n",
        "- The loss function takes a 'vector of ground truth values' and a 'vector of logits'. It then returns a 'scalar loss' for each example we provide.\n",
        "\n",
        "2) What does this scalar loss represent mathematically?\n",
        "- This loss is equal to the 'negative log probability' of the true class. If the model is sure of the correct class, the loss becomes 0."
      ],
      "metadata": {
        "id": "1hR2IqiMWNAq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn= tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "# testing the loss function on the untrained model\n",
        "loss_fn(y_train[0:1], model(x_train[:1])) # the 2nd parameter is just sample_predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFLn5ul5UoXK",
        "outputId": "535cf2b3-deca-45e0-ee1d-110794f31b39"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=3.0136228>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Although have now have our data, model and loss function, before we start training, we still need to configure and compile the model (last step)."
      ],
      "metadata": {
        "id": "OMwI0Z_JbH_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=loss_fn,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "n_jErVTHbUtM"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "aWoAPfhIeMgZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qc0-naTIeOr3",
        "outputId": "1f08c13c-a3e1-4dac-f241-4818e28afa44"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2941 - accuracy: 0.9136\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1435 - accuracy: 0.9575\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1053 - accuracy: 0.9679\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0857 - accuracy: 0.9733\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0744 - accuracy: 0.9770\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ddbca9b3df0>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate"
      ],
      "metadata": {
        "id": "zgPy8vkdlVLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test, y_test, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EW94C5dlXts",
        "outputId": "f245ffd2-1fd8-4637-90af-42ed1a26332f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 - 1s - loss: 0.0726 - accuracy: 0.9781 - 746ms/epoch - 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07257018238306046, 0.9781000018119812]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Probability Output"
      ],
      "metadata": {
        "id": "2A6ZyWZolyIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "probability_model = tf.keras.Sequential([\n",
        "    model,\n",
        "    tf.keras.layers.Softmax()\n",
        "])\n",
        "probability_model(x_test[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bULnxp-Ql1C0",
        "outputId": "3c7c99a5-bb6a-4bd6-ec64-44372ff7426e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 10), dtype=float32, numpy=\n",
              "array([[4.18566382e-09, 7.25947302e-09, 1.97881172e-06, 2.54628430e-05,\n",
              "        9.27672609e-12, 2.29215942e-07, 9.29694554e-14, 9.99971986e-01,\n",
              "        3.75240745e-08, 2.39933058e-07],\n",
              "       [1.71039574e-07, 5.38491295e-05, 9.99937415e-01, 8.15597105e-06,\n",
              "        2.18755767e-15, 3.20579034e-07, 1.87809999e-08, 8.62294351e-12,\n",
              "        9.73333556e-08, 2.36361935e-14],\n",
              "       [8.10277743e-06, 9.98400152e-01, 3.88404209e-04, 1.08080267e-05,\n",
              "        8.70907661e-06, 4.14348915e-06, 1.85158606e-05, 8.72604491e-04,\n",
              "        2.87413772e-04, 1.16955778e-06],\n",
              "       [9.99435484e-01, 3.03244252e-09, 3.43543652e-04, 1.69965162e-07,\n",
              "        2.49371897e-06, 1.18702355e-05, 9.62124323e-05, 9.37564691e-05,\n",
              "        2.49177656e-08, 1.64682642e-05],\n",
              "       [1.40902125e-06, 4.72845541e-09, 6.21301115e-06, 2.97799630e-07,\n",
              "        9.98634279e-01, 1.19562992e-05, 1.47840012e-06, 3.38060963e-05,\n",
              "        5.25195787e-07, 1.30996923e-03]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    }
  ]
}